{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WON'T WORK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>pop_count_adj</th>\n",
       "      <th>crime_number_adj</th>\n",
       "      <th>crime_score_adj</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>34.164179</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>173750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.036739</td>\n",
       "      <td>46577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>29.994709</td>\n",
       "      <td>0.005820</td>\n",
       "      <td>0.036138</td>\n",
       "      <td>54743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>26.867322</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.057666</td>\n",
       "      <td>66250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71</td>\n",
       "      <td>23.702381</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>144031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72</td>\n",
       "      <td>22.318182</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>74080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73</td>\n",
       "      <td>20.410959</td>\n",
       "      <td>0.083938</td>\n",
       "      <td>0.494760</td>\n",
       "      <td>76139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>74</td>\n",
       "      <td>18.833787</td>\n",
       "      <td>0.059292</td>\n",
       "      <td>0.356403</td>\n",
       "      <td>136237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81</td>\n",
       "      <td>15.320755</td>\n",
       "      <td>0.311297</td>\n",
       "      <td>1.795071</td>\n",
       "      <td>142213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>86</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.513434</td>\n",
       "      <td>2.795843</td>\n",
       "      <td>125278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>88</td>\n",
       "      <td>12.978261</td>\n",
       "      <td>0.748043</td>\n",
       "      <td>4.308152</td>\n",
       "      <td>213889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>89</td>\n",
       "      <td>11.985915</td>\n",
       "      <td>0.520035</td>\n",
       "      <td>3.188803</td>\n",
       "      <td>141172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>91</td>\n",
       "      <td>10.734127</td>\n",
       "      <td>0.234167</td>\n",
       "      <td>1.358234</td>\n",
       "      <td>164903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>92</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.473106</td>\n",
       "      <td>2.863789</td>\n",
       "      <td>145694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>94</td>\n",
       "      <td>6.378049</td>\n",
       "      <td>1.041707</td>\n",
       "      <td>7.193049</td>\n",
       "      <td>144036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>95</td>\n",
       "      <td>6.941057</td>\n",
       "      <td>0.372317</td>\n",
       "      <td>2.405183</td>\n",
       "      <td>104853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>6.581967</td>\n",
       "      <td>0.005533</td>\n",
       "      <td>0.034877</td>\n",
       "      <td>134036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>101</td>\n",
       "      <td>2.882812</td>\n",
       "      <td>0.335547</td>\n",
       "      <td>1.801964</td>\n",
       "      <td>144444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>103</td>\n",
       "      <td>5.012195</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.021366</td>\n",
       "      <td>121818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.190541</td>\n",
       "      <td>1.087730</td>\n",
       "      <td>153810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>105</td>\n",
       "      <td>3.979339</td>\n",
       "      <td>0.137066</td>\n",
       "      <td>0.914215</td>\n",
       "      <td>250001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029868</td>\n",
       "      <td>0.194912</td>\n",
       "      <td>111250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>107</td>\n",
       "      <td>1.420668</td>\n",
       "      <td>0.137582</td>\n",
       "      <td>0.751192</td>\n",
       "      <td>229083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>108</td>\n",
       "      <td>3.953333</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>121818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>109</td>\n",
       "      <td>2.636119</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.008369</td>\n",
       "      <td>176510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>110</td>\n",
       "      <td>1.684211</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>0.024795</td>\n",
       "      <td>120682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>112</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.004646</td>\n",
       "      <td>0.026637</td>\n",
       "      <td>250001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster  pop_count_adj  crime_number_adj  crime_score_adj  income\n",
       "0        61      34.164179          0.000560         0.003470  173750\n",
       "1        63      31.000000          0.005815         0.036739   46577\n",
       "2        65      29.994709          0.005820         0.036138   54743\n",
       "3        67      26.867322          0.010000         0.057666   66250\n",
       "4        71      23.702381          0.000357         0.002659  144031\n",
       "5        72      22.318182          0.001429         0.008636   74080\n",
       "6        73      20.410959          0.083938         0.494760   76139\n",
       "7        74      18.833787          0.059292         0.356403  136237\n",
       "8        81      15.320755          0.311297         1.795071  142213\n",
       "9        86      14.000000          0.513434         2.795843  125278\n",
       "10       88      12.978261          0.748043         4.308152  213889\n",
       "11       89      11.985915          0.520035         3.188803  141172\n",
       "12       91      10.734127          0.234167         1.358234  164903\n",
       "13       92       9.000000          0.473106         2.863789  145694\n",
       "14       94       6.378049          1.041707         7.193049  144036\n",
       "15       95       6.941057          0.372317         2.405183  104853\n",
       "16      100       6.581967          0.005533         0.034877  134036\n",
       "17      101       2.882812          0.335547         1.801964  144444\n",
       "18      103       5.012195          0.003512         0.021366  121818\n",
       "19      104       1.000000          0.190541         1.087730  153810\n",
       "20      105       3.979339          0.137066         0.914215  250001\n",
       "21      106       1.000000          0.029868         0.194912  111250\n",
       "22      107       1.420668          0.137582         0.751192  229083\n",
       "23      108       3.953333          0.006800         0.039800  121818\n",
       "24      109       2.636119          0.001334         0.008369  176510\n",
       "25      110       1.684211          0.003830         0.024795  120682\n",
       "26      112       0.026549          0.004646         0.026637  250001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('edited_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['pop_count_adj', 'income']]\n",
    "y = df['crime_score_adj'] * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training, validation, and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define polynomial features and fit to training data\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define linear regression model and fit to polynomial features\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on validation set and calculate mean squared error\n",
    "X_val_poly = poly.transform(X_val)\n",
    "y_val_pred = reg.predict(X_val_poly)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set and calculate mean squared error\n",
    "X_test_poly = poly.transform(X_test)\n",
    "y_test_pred = reg.predict(X_test_poly)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 5600.2950184533975\n",
      "Test MSE: 19467.693619835514\n"
     ]
    }
   ],
   "source": [
    "print('Validation MSE:', val_mse)\n",
    "print('Test MSE:', test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\PycharmProjects\\SafeRoute\\venv\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-88.60012896])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred = poly.transform(np.array([[10, 50000]]))\n",
    "y_pred = reg.predict(x_pred)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
